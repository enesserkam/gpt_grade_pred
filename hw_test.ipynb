{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T23:13:28.844337Z",
     "start_time": "2024-01-18T23:13:25.848741Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import graphviz\n",
    "\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from collections import Counter\n",
    "import gensim\n",
    "import nltk\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T23:14:10.535452Z",
     "start_time": "2024-01-18T23:13:28.849527Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 188/188 [00:41<00:00,  4.51it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = \"test/html/*.html\"\n",
    "\n",
    "code2convos = dict()\n",
    "\n",
    "pbar = tqdm.tqdm(sorted(list(glob(data_path))))\n",
    "for path in pbar:\n",
    "    # print(Path.cwd() / path)\n",
    "    file_code = os.path.basename(path).split(\".\")[0]\n",
    "    with open(path, \"r\", encoding=\"latin1\") as fh:\n",
    "            \n",
    "        # get the file id to use it as key later on\n",
    "        fid = os.path.basename(path).split(\".\")[0]\n",
    "\n",
    "        # read the html file\n",
    "        html_page = fh.read()\n",
    "\n",
    "        # parse the html file with bs4 so we can extract needed stuff\n",
    "        soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "\n",
    "        # grab the conversations with the data-testid pattern\n",
    "        data_test_id_pattern = re.compile(r\"conversation-turn-[0-9]+\")\n",
    "        conversations = soup.find_all(\"div\", attrs={\"data-testid\": data_test_id_pattern})\n",
    "\n",
    "        convo_texts = []\n",
    "\n",
    "        for i, convo in enumerate(conversations):\n",
    "            convo = convo.find_all(\"div\", attrs={\"data-message-author-role\":re.compile( r\"[user|assistant]\") })\n",
    "            if len(convo) > 0:\n",
    "                role = convo[0].get(\"data-message-author-role\")\n",
    "                convo_texts.append({\n",
    "                        \"role\" : role,\n",
    "                        \"text\" : convo[0].text\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "        code2convos[file_code] = convo_texts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Things to do:\n",
    "- Prompt matching with questions\n",
    "- Feature Engineering\n",
    "- Question Grades preparation\n",
    "- Train/Test split\n",
    "- Fitting a model for predicting the scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Matching\n",
    "> We want to match the prompts with the questions in the Homework Let's\n",
    "> do it with a simple term frequency vectorizing method. For each prompt,\n",
    "> we will come with a vector that represents it. We will do the same\n",
    "> thing with each of the homework questions. Then, we will calculate the\n",
    "> vectors distanance to do the matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T23:16:37.614819Z",
     "start_time": "2024-01-18T23:16:37.604307Z"
    }
   },
   "outputs": [],
   "source": [
    "prompts = []\n",
    "code2prompts = defaultdict(list)\n",
    "for code , convos in code2convos.items():\n",
    "    user_prompts = []\n",
    "    for conv in convos:\n",
    "        if conv[\"role\"] == \"user\":\n",
    "            prompts.append(conv[\"text\"])\n",
    "            user_prompts.append(conv[\"text\"])\n",
    "    code2prompts[code] = user_prompts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T23:16:41.511669Z",
     "start_time": "2024-01-18T23:16:41.498957Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"# Hypothetical Feature 1: Daily Fish Consumption\\nX_train['Daily Fish Consumption'] = X_train['body_mass_g'] / X_train.groupby('diet')['body_mass_g'].transform('mean')\\n\\n# Hypothetical Feature 2: Activity Index\\nX_train['Activity Index'] = X_train['flipper_length_mm'] / X_train['body_mass_g']\\n\\n# Display the correlations with the target variable\\ncorrelation_feature1 = X_train['Daily Fish Consumption'].corr(y_train)\\ncorrelation_feature2 = X_train['Activity Index'].corr(y_train)\\n\\n(correlation_feature1, correlation_feature2)\\n THÄ°S Ä°S THE CODE\""
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T23:16:43.549239Z",
     "start_time": "2024-01-18T23:16:43.535999Z"
    }
   },
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"\"\"Initialize\n",
    "*   First make a copy of the notebook given to you as a starter.\n",
    "*   Make sure you choose Connect form upper right.\n",
    "*   You may upload the data to the section on your left on Colab, than right click on the .csv file and get the path of the file by clicking on \"Copy Path\". You will be using it when loading the data.\n",
    "\n",
    "\"\"\",\n",
    "#####################\n",
    "    \"\"\"Load training dataset (5 pts)\n",
    "    *  Read the .csv file with the pandas library\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Understanding the dataset & Preprocessing (15 pts)\n",
    "Understanding the Dataset: (5 pts)\n",
    "> - Find the shape of the dataset (number of samples & number of attributes). (Hint: You can use the **shape** function)\n",
    "> - Display variable names (both dependent and independent).\n",
    "> - Display the summary of the dataset. (Hint: You can use the **info** function)\n",
    "> - Display the first 5 rows from training dataset. (Hint: You can use the **head** function)\n",
    "Preprocessing: (10 pts)\n",
    "\n",
    "> - Check if there are any missing values in the dataset. If there are, you can either drop these values or fill it with most common values in corresponding rows. **Be careful that you have enough data for training the  model.**\n",
    "\n",
    "> - Encode categorical labels with the mappings given in the cell below. (Hint: You can use **map** function)\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Set X & y, split data (5 pts)\n",
    "\n",
    "*   Shuffle the dataset.\n",
    "*   Seperate your dependent variable X, and your independent variable y. The column health_metrics is y, the rest is X.\n",
    "*   Split training and test sets as 80% and 20%, respectively.\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Features and Correlations (10 pts)\n",
    "\n",
    "* Correlations of features with health (4 points)\n",
    "Calculate the correlations for all features in dataset. Highlight any strong correlations with the target variable. Plot your results in a heatmap.\n",
    "\n",
    "* Feature Selection (3 points)\n",
    "Select a subset of features that are likely strong predictors, justifying your choices based on the computed correlations.\n",
    "\n",
    "* Hypothetical Driver Features (3 points)\n",
    "Propose two hypothetical features that could enhance the model's predictive accuracy for Y, explaining how they might be derived and their expected impact. Show the resulting correlations with target variable.\n",
    "\n",
    "* __Note:__ You get can get help from GPT.\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Tune Hyperparameters (20 pts)\n",
    "* Choose 2 hyperparameters to tune. You can use the Scikit learn decision tree documentation for the available hyperparameters *(Hyperparameters are listed under \"Parameters\" in the documentation)*. Use GridSearchCV for hyperparameter tuning, with a cross-validation value of 5. Use validation accuracy to pick the best hyper-parameter values. (15 pts)\n",
    "-Explain the hyperparameters you chose to tune. *(What are the hyperparameters you chose? Why did you choose them?)* (5 pts)\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Re-train and plot the decision tree with the hyperparameters you have chosen (15 pts)\n",
    "- Re-train model with the hyperparameters you have chosen in part 5). (10 pts)\n",
    "- Plot the tree you have trained. (5 pts)\n",
    "Hint: You can import the **plot_tree** function from the sklearn library.\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Test your classifier on the test set (20 pts)\n",
    "- Predict the labels of testing data using the tree you have trained in step 6. (10 pts)\n",
    "- Report the classification accuracy. (2 pts)\n",
    "- Plot & investigate the confusion matrix. Fill the following blanks. (8 pts)\n",
    "> The model most frequently mistakes class(es) _________ for class(es) _________.\n",
    "Hint: You can use the confusion_matrix function from sklearn.metrics\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Find the information gain on the first split (10 pts)\"\"\",\n",
    "#####################\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nglove_input_file = 'glove/glove.6B.100d.txt'\\nword2vec_output_file = 'glove/glove.6B.100d.word2vec.txt'\\nglove2word2vec(glove_input_file, word2vec_output_file)\\n\\nglove_input_file = 'glove/glove.6B.50d.txt'\\nword2vec_output_file = 'glove/glove.6B.50d.word2vec.txt'\\nglove2word2vec(glove_input_file, word2vec_output_file)\\n\\nglove_input_file = 'glove/glove.6B.200d.txt'\\nword2vec_output_file = 'glove/glove.6B.200d.word2vec.txt'\\nglove2word2vec(glove_input_file, word2vec_output_file)\\n\""
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "glove_input_file = 'glove/glove.6B.100d.txt'\n",
    "word2vec_output_file = 'glove/glove.6B.100d.word2vec.txt'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\n",
    "glove_input_file = 'glove/glove.6B.50d.txt'\n",
    "word2vec_output_file = 'glove/glove.6B.50d.word2vec.txt'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\n",
    "glove_input_file = 'glove/glove.6B.200d.txt'\n",
    "word2vec_output_file = 'glove/glove.6B.200d.word2vec.txt'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:16:45.776417Z",
     "start_time": "2024-01-18T23:16:45.764870Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [],
   "source": [
    "glove_model = KeyedVectors.load_word2vec_format('glove/glove.6B.50d.word2vec.txt', binary=False)\n",
    "def preprocess_and_tokenize(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    return [word for word in words if word.isalpha()]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:17:00.243383Z",
     "start_time": "2024-01-18T23:16:48.339219Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T23:17:41.732302Z",
     "start_time": "2024-01-18T23:17:35.615769Z"
    }
   },
   "outputs": [],
   "source": [
    "def vectorize_prompts(prompts, model):\n",
    "    vectorized = []\n",
    "    for prompt in prompts:\n",
    "        words = preprocess_and_tokenize(prompt)\n",
    "        word_vectors = [model[word] for word in words if word in model.key_to_index]\n",
    "\n",
    "        if len(word_vectors) == 0:\n",
    "            vectorized.append(np.zeros(model.vector_size))  \n",
    "        else:\n",
    "            vectorized.append(np.mean(word_vectors, axis=0)) \n",
    "\n",
    "    return pd.DataFrame(vectorized)\n",
    "\n",
    "code2prompts_glove = dict()\n",
    "\n",
    "for code, user_prompts in code2prompts.items():\n",
    "    if len(user_prompts) > 0:\n",
    "        vectorized_df = vectorize_prompts(user_prompts, glove_model)\n",
    "        code2prompts_glove[code] = vectorized_df\n",
    "    else:\n",
    "        print(f\"{code}.html has no prompts\")\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer = vectorizer.fit(prompts + questions)\n",
    "questions_TF_IDF = pd.DataFrame(vectorizer.transform(questions).toarray(), columns=vectorizer.get_feature_names_out())\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:18:20.988289Z",
     "start_time": "2024-01-18T23:18:20.484680Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [],
   "source": [
    "code2prompts_tf_idf = dict()\n",
    "for code, user_prompts in code2prompts.items():\n",
    "    if len(user_prompts) == 0:\n",
    "        print(code+\".html\")\n",
    "        continue\n",
    "    prompts_TF_IDF = pd.DataFrame(vectorizer.transform(user_prompts).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    code2prompts_tf_idf[code] = prompts_TF_IDF"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:18:33.159586Z",
     "start_time": "2024-01-18T23:18:30.808988Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T23:18:48.898582Z",
     "start_time": "2024-01-18T23:18:34.854523Z"
    }
   },
   "outputs": [],
   "source": [
    "code2cosine = dict()\n",
    "for code, user_prompts_tf_idf in code2prompts_tf_idf.items():\n",
    "    code2cosine[code] = pd.DataFrame(cosine_similarity(questions_TF_IDF,user_prompts_tf_idf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "outputs": [],
   "source": [
    "question_of_prompts = dict()\n",
    "\n",
    "for code, df in code2cosine.items():\n",
    "    max_indices = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        max_index = df[col].idxmax()\n",
    "\n",
    "        max_indices.append(max_index)\n",
    "\n",
    "    question_of_prompts[code] = max_indices\n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:18:53.170365Z",
     "start_time": "2024-01-18T23:18:52.063645Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "outputs": [],
   "source": [
    "num_questions = len(questions)\n",
    "\n",
    "new_code_counts = dict()\n",
    "\n",
    "for code, indices in question_of_prompts.items():\n",
    "    counts = Counter(indices)\n",
    "\n",
    "    count_vector = [counts.get(i, 0) for i in range(num_questions)]\n",
    "\n",
    "    new_code_counts[code] = count_vector\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:18:54.384596Z",
     "start_time": "2024-01-18T23:18:54.371272Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "outputs": [
    {
     "data": {
      "text/plain": "                                     q0_feature_0 q0_feature_1 q0_feature_2  \\\ncode                                                                          \n00941713-c3a2-4d27-81dc-cd447ace4a47          0.0          0.0          0.0   \n00aea02f-a95a-4c04-8be3-777461732cdf         23.0         23.0         23.0   \n04fdb619-d902-4e98-a5e9-a8198bfe047c         19.5         19.5         19.5   \n05029661-f8d8-441b-9cab-3c79f28a8b26    11.666667    11.666667    11.666667   \n059a146e-a37c-498f-8c0b-5a78204249cb          0.0          0.0          0.0   \n\n                                     q0_feature_3 q0_feature_4 q0_feature_5  \\\ncode                                                                          \n00941713-c3a2-4d27-81dc-cd447ace4a47          0.0          0.0          0.0   \n00aea02f-a95a-4c04-8be3-777461732cdf         23.0         23.0         23.0   \n04fdb619-d902-4e98-a5e9-a8198bfe047c         19.5         19.5         19.5   \n05029661-f8d8-441b-9cab-3c79f28a8b26    11.666667    11.666667    11.666667   \n059a146e-a37c-498f-8c0b-5a78204249cb          0.0          0.0          0.0   \n\n                                     q0_feature_6 q0_feature_7 q0_feature_8  \\\ncode                                                                          \n00941713-c3a2-4d27-81dc-cd447ace4a47          0.0          0.0          0.0   \n00aea02f-a95a-4c04-8be3-777461732cdf         23.0         23.0         23.0   \n04fdb619-d902-4e98-a5e9-a8198bfe047c         19.5         19.5         19.5   \n05029661-f8d8-441b-9cab-3c79f28a8b26    11.666667    11.666667    11.666667   \n059a146e-a37c-498f-8c0b-5a78204249cb          0.0          0.0          0.0   \n\n                                     q0_feature_9  ... q8_feature_40  \\\ncode                                               ...                 \n00941713-c3a2-4d27-81dc-cd447ace4a47          0.0  ...           0.0   \n00aea02f-a95a-4c04-8be3-777461732cdf         23.0  ...          19.5   \n04fdb619-d902-4e98-a5e9-a8198bfe047c         19.5  ...          29.0   \n05029661-f8d8-441b-9cab-3c79f28a8b26    11.666667  ...           0.0   \n059a146e-a37c-498f-8c0b-5a78204249cb          0.0  ...          19.0   \n\n                                     q8_feature_41 q8_feature_42  \\\ncode                                                               \n00941713-c3a2-4d27-81dc-cd447ace4a47           0.0           0.0   \n00aea02f-a95a-4c04-8be3-777461732cdf          19.5          19.5   \n04fdb619-d902-4e98-a5e9-a8198bfe047c          29.0          29.0   \n05029661-f8d8-441b-9cab-3c79f28a8b26           0.0           0.0   \n059a146e-a37c-498f-8c0b-5a78204249cb          19.0          19.0   \n\n                                     q8_feature_43 q8_feature_44  \\\ncode                                                               \n00941713-c3a2-4d27-81dc-cd447ace4a47           0.0           0.0   \n00aea02f-a95a-4c04-8be3-777461732cdf          19.5          19.5   \n04fdb619-d902-4e98-a5e9-a8198bfe047c          29.0          29.0   \n05029661-f8d8-441b-9cab-3c79f28a8b26           0.0           0.0   \n059a146e-a37c-498f-8c0b-5a78204249cb          19.0          19.0   \n\n                                     q8_feature_45 q8_feature_46  \\\ncode                                                               \n00941713-c3a2-4d27-81dc-cd447ace4a47           0.0           0.0   \n00aea02f-a95a-4c04-8be3-777461732cdf          19.5          19.5   \n04fdb619-d902-4e98-a5e9-a8198bfe047c          29.0          29.0   \n05029661-f8d8-441b-9cab-3c79f28a8b26           0.0           0.0   \n059a146e-a37c-498f-8c0b-5a78204249cb          19.0          19.0   \n\n                                     q8_feature_47 q8_feature_48 q8_feature_49  \ncode                                                                            \n00941713-c3a2-4d27-81dc-cd447ace4a47           0.0           0.0           0.0  \n00aea02f-a95a-4c04-8be3-777461732cdf          19.5          19.5          19.5  \n04fdb619-d902-4e98-a5e9-a8198bfe047c          29.0          29.0          29.0  \n05029661-f8d8-441b-9cab-3c79f28a8b26           0.0           0.0           0.0  \n059a146e-a37c-498f-8c0b-5a78204249cb          19.0          19.0          19.0  \n\n[5 rows x 450 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>q0_feature_0</th>\n      <th>q0_feature_1</th>\n      <th>q0_feature_2</th>\n      <th>q0_feature_3</th>\n      <th>q0_feature_4</th>\n      <th>q0_feature_5</th>\n      <th>q0_feature_6</th>\n      <th>q0_feature_7</th>\n      <th>q0_feature_8</th>\n      <th>q0_feature_9</th>\n      <th>...</th>\n      <th>q8_feature_40</th>\n      <th>q8_feature_41</th>\n      <th>q8_feature_42</th>\n      <th>q8_feature_43</th>\n      <th>q8_feature_44</th>\n      <th>q8_feature_45</th>\n      <th>q8_feature_46</th>\n      <th>q8_feature_47</th>\n      <th>q8_feature_48</th>\n      <th>q8_feature_49</th>\n    </tr>\n    <tr>\n      <th>code</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>00941713-c3a2-4d27-81dc-cd447ace4a47</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>00aea02f-a95a-4c04-8be3-777461732cdf</th>\n      <td>23.0</td>\n      <td>23.0</td>\n      <td>23.0</td>\n      <td>23.0</td>\n      <td>23.0</td>\n      <td>23.0</td>\n      <td>23.0</td>\n      <td>23.0</td>\n      <td>23.0</td>\n      <td>23.0</td>\n      <td>...</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>19.5</td>\n    </tr>\n    <tr>\n      <th>04fdb619-d902-4e98-a5e9-a8198bfe047c</th>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>19.5</td>\n      <td>...</td>\n      <td>29.0</td>\n      <td>29.0</td>\n      <td>29.0</td>\n      <td>29.0</td>\n      <td>29.0</td>\n      <td>29.0</td>\n      <td>29.0</td>\n      <td>29.0</td>\n      <td>29.0</td>\n      <td>29.0</td>\n    </tr>\n    <tr>\n      <th>05029661-f8d8-441b-9cab-3c79f28a8b26</th>\n      <td>11.666667</td>\n      <td>11.666667</td>\n      <td>11.666667</td>\n      <td>11.666667</td>\n      <td>11.666667</td>\n      <td>11.666667</td>\n      <td>11.666667</td>\n      <td>11.666667</td>\n      <td>11.666667</td>\n      <td>11.666667</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>059a146e-a37c-498f-8c0b-5a78204249cb</th>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>19.0</td>\n      <td>19.0</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 450 columns</p>\n</div>"
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vector_size = 50   \n",
    "\n",
    "final_df = pd.DataFrame(index=code2prompts_glove.keys(), columns=[f'q{i}_feature_{j}' for i in range(num_questions) for j in range(vector_size)])\n",
    "\n",
    "for code in code2prompts_glove.keys():\n",
    "    glove_vectors = code2prompts_glove[code]\n",
    "    question_indices = question_of_prompts[code]\n",
    "\n",
    "    summed_vectors = np.zeros((num_questions, vector_size))\n",
    "    prompt_counts = Counter(question_indices)\n",
    "\n",
    "    for vector, question_idx in zip(glove_vectors, question_indices):\n",
    "        scaled_vector = vector / prompt_counts[question_idx]\n",
    "        summed_vectors[question_idx] += scaled_vector\n",
    "\n",
    "    for i in range(num_questions):\n",
    "        column_labels = [f'q{i}_feature_{j}' for j in range(vector_size)]\n",
    "        final_df.loc[code, column_labels] = summed_vectors[i]\n",
    "\n",
    "final_df.rename_axis('code', inplace=True)\n",
    "final_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:18:58.186706Z",
     "start_time": "2024-01-18T23:18:56.203776Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "normalized_data = scaler.fit_transform(final_df)\n",
    "\n",
    "normalized_df = pd.DataFrame(normalized_data, index=final_df.index, columns=final_df.columns)\n",
    "\n",
    "normalized_df.rename_axis('code', inplace=True)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:19:01.833665Z",
     "start_time": "2024-01-18T23:19:01.746458Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "- Number of prompts that a user asked\n",
    "- Number of complaints that a user makes e.g \"the code gives this error!\"\n",
    "- User prompts average number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "outputs": [],
   "source": [
    "coefficients = [0.1,0.05,0.15,0.05,0.1,0.2,0.15,0.1,0.1]\n",
    "\n",
    "modified_code_counts = {}\n",
    "\n",
    "for code, count_vector in new_code_counts.items():\n",
    "    modified_vector = [count * coeff for count, coeff in zip(count_vector, coefficients)]\n",
    "    modified_code_counts[code] = modified_vector\n",
    "\n",
    "modified_counts_df = pd.DataFrame.from_dict(modified_code_counts, orient='index')\n",
    "\n",
    "modified_counts_df.index.name = 'code'\n",
    "\n",
    "extended_df = normalized_df.merge(modified_counts_df, left_on='code', right_index=True)\n",
    "\n",
    "modified_count_col_names = [f'modified_count_{i}' for i in range(num_questions)]\n",
    "extended_df.rename(columns=dict(zip(range(num_questions), modified_count_col_names)), inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:19:09.899516Z",
     "start_time": "2024-01-18T23:19:09.890785Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "outputs": [],
   "source": [
    "code2questionmapping = dict()\n",
    "for code, cosine_scores in code2cosine.items():\n",
    "    code2questionmapping[code] = code2cosine[code].max(axis=1).tolist()\n",
    "\n",
    "question_mapping_scores = pd.DataFrame(code2questionmapping).T\n",
    "question_mapping_scores.reset_index(inplace=True)\n",
    "question_mapping_scores.rename(columns={i: f\"Q_{i}\" for i in range(len(questions))}, inplace=True)\n",
    "question_mapping_scores.rename(columns={\"index\" : \"code\"}, inplace=True)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:19:15.861776Z",
     "start_time": "2024-01-18T23:19:15.783901Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "outputs": [
    {
     "data": {
      "text/plain": "(188, 469)"
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df = question_mapping_scores.merge(extended_df, on='code', how='left')\n",
    "# merged_df = question_mapping_scores.merge(modified_counts_df, on='code', how='left')\n",
    "merged_df.shape"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:19:21.081745Z",
     "start_time": "2024-01-18T23:19:21.065486Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "outputs": [
    {
     "data": {
      "text/plain": "                                   code       Q_0       Q_1       Q_2  \\\n0  00941713-c3a2-4d27-81dc-cd447ace4a47  0.158311  0.104992  0.284418   \n1  00aea02f-a95a-4c04-8be3-777461732cdf  0.235186  0.195519  0.381383   \n2  04fdb619-d902-4e98-a5e9-a8198bfe047c  0.182626  0.353836  0.805640   \n3  05029661-f8d8-441b-9cab-3c79f28a8b26  0.223914  0.607638  0.805640   \n4  059a146e-a37c-498f-8c0b-5a78204249cb  0.190508  0.438151  0.843587   \n\n        Q_3       Q_4       Q_5       Q_6       Q_7       Q_8  ...  \\\n0  0.085794  0.288204  0.956225  0.342733  0.257241  0.119235  ...   \n1  0.601936  0.668807  0.212292  0.556832  0.526469  0.555292  ...   \n2  0.824759  0.763438  0.815282  0.733843  0.426418  0.738563  ...   \n3  0.920694  0.720973  0.988016  0.406387  1.000000  0.812817  ...   \n4  0.953558  0.710209  0.210283  0.333815  0.770213  0.555292  ...   \n\n   q8_feature_49  modified_count_0  modified_count_1  modified_count_2  \\\n0      -1.067676               0.0              0.00              0.60   \n1       0.333724               0.2              0.05              2.70   \n2       1.016457               0.4              0.05              1.05   \n3      -1.067676               0.3              0.20              1.95   \n4       0.297791               0.0              0.10              1.05   \n\n   modified_count_3  modified_count_4  modified_count_5  modified_count_6  \\\n0              0.00               0.2               0.6              0.15   \n1              0.20               0.2               0.8              0.30   \n2              0.20               0.6               0.6              0.45   \n3              0.35               1.7               1.2              0.75   \n4              0.20               0.3               0.0              0.15   \n\n   modified_count_7  modified_count_8  \n0               0.2               0.0  \n1               0.4               0.2  \n2               0.2               0.3  \n3               0.4               0.4  \n4               0.2               0.1  \n\n[5 rows x 469 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code</th>\n      <th>Q_0</th>\n      <th>Q_1</th>\n      <th>Q_2</th>\n      <th>Q_3</th>\n      <th>Q_4</th>\n      <th>Q_5</th>\n      <th>Q_6</th>\n      <th>Q_7</th>\n      <th>Q_8</th>\n      <th>...</th>\n      <th>q8_feature_49</th>\n      <th>modified_count_0</th>\n      <th>modified_count_1</th>\n      <th>modified_count_2</th>\n      <th>modified_count_3</th>\n      <th>modified_count_4</th>\n      <th>modified_count_5</th>\n      <th>modified_count_6</th>\n      <th>modified_count_7</th>\n      <th>modified_count_8</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>00941713-c3a2-4d27-81dc-cd447ace4a47</td>\n      <td>0.158311</td>\n      <td>0.104992</td>\n      <td>0.284418</td>\n      <td>0.085794</td>\n      <td>0.288204</td>\n      <td>0.956225</td>\n      <td>0.342733</td>\n      <td>0.257241</td>\n      <td>0.119235</td>\n      <td>...</td>\n      <td>-1.067676</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.60</td>\n      <td>0.00</td>\n      <td>0.2</td>\n      <td>0.6</td>\n      <td>0.15</td>\n      <td>0.2</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>00aea02f-a95a-4c04-8be3-777461732cdf</td>\n      <td>0.235186</td>\n      <td>0.195519</td>\n      <td>0.381383</td>\n      <td>0.601936</td>\n      <td>0.668807</td>\n      <td>0.212292</td>\n      <td>0.556832</td>\n      <td>0.526469</td>\n      <td>0.555292</td>\n      <td>...</td>\n      <td>0.333724</td>\n      <td>0.2</td>\n      <td>0.05</td>\n      <td>2.70</td>\n      <td>0.20</td>\n      <td>0.2</td>\n      <td>0.8</td>\n      <td>0.30</td>\n      <td>0.4</td>\n      <td>0.2</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>04fdb619-d902-4e98-a5e9-a8198bfe047c</td>\n      <td>0.182626</td>\n      <td>0.353836</td>\n      <td>0.805640</td>\n      <td>0.824759</td>\n      <td>0.763438</td>\n      <td>0.815282</td>\n      <td>0.733843</td>\n      <td>0.426418</td>\n      <td>0.738563</td>\n      <td>...</td>\n      <td>1.016457</td>\n      <td>0.4</td>\n      <td>0.05</td>\n      <td>1.05</td>\n      <td>0.20</td>\n      <td>0.6</td>\n      <td>0.6</td>\n      <td>0.45</td>\n      <td>0.2</td>\n      <td>0.3</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>05029661-f8d8-441b-9cab-3c79f28a8b26</td>\n      <td>0.223914</td>\n      <td>0.607638</td>\n      <td>0.805640</td>\n      <td>0.920694</td>\n      <td>0.720973</td>\n      <td>0.988016</td>\n      <td>0.406387</td>\n      <td>1.000000</td>\n      <td>0.812817</td>\n      <td>...</td>\n      <td>-1.067676</td>\n      <td>0.3</td>\n      <td>0.20</td>\n      <td>1.95</td>\n      <td>0.35</td>\n      <td>1.7</td>\n      <td>1.2</td>\n      <td>0.75</td>\n      <td>0.4</td>\n      <td>0.4</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>059a146e-a37c-498f-8c0b-5a78204249cb</td>\n      <td>0.190508</td>\n      <td>0.438151</td>\n      <td>0.843587</td>\n      <td>0.953558</td>\n      <td>0.710209</td>\n      <td>0.210283</td>\n      <td>0.333815</td>\n      <td>0.770213</td>\n      <td>0.555292</td>\n      <td>...</td>\n      <td>0.297791</td>\n      <td>0.0</td>\n      <td>0.10</td>\n      <td>1.05</td>\n      <td>0.20</td>\n      <td>0.3</td>\n      <td>0.0</td>\n      <td>0.15</td>\n      <td>0.2</td>\n      <td>0.1</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 469 columns</p>\n</div>"
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged_df.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:26:08.022562Z",
     "start_time": "2024-01-18T23:26:07.927332Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging scores with features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting and Analyzing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                     Code Predicted Grade\n",
      "0    00941713-c3a2-4d27-81dc-cd447ace4a47            86.1\n",
      "1    00aea02f-a95a-4c04-8be3-777461732cdf          97.425\n",
      "2    04fdb619-d902-4e98-a5e9-a8198bfe047c           98.45\n",
      "3    05029661-f8d8-441b-9cab-3c79f28a8b26          92.675\n",
      "4    059a146e-a37c-498f-8c0b-5a78204249cb          95.575\n",
      "..                                    ...             ...\n",
      "183  fab774ac-38c8-4d86-910c-7ad0fa8470c5          90.825\n",
      "184  fac3042d-d72d-43a7-9170-a424e3061fac           96.25\n",
      "185  fbf473eb-ea6f-4a4a-b2d8-405bc09f9850          95.875\n",
      "186  fccd270d-63f8-42b6-b73e-13f6d3e5f612           96.25\n",
      "187  fe81cca3-d9c2-4d82-97a4-9cc1444ea219           95.85\n",
      "\n",
      "[188 rows x 2 columns]\n"
     ]
    }
   ],
   "source": [
    "from joblib import load\n",
    "\n",
    "regressor = load('412_rf_model.joblib')\n",
    "scaler = load('scaler.joblib')\n",
    "\n",
    "X = merged_df.iloc[:, 1:].to_numpy()\n",
    "y_test_pred = regressor.predict(X)\n",
    "\n",
    "adjusted_pred = scaler.inverse_transform(y_test_pred.reshape(-1, 1))\n",
    "original_grade_pred = adjusted_pred + 70\n",
    "\n",
    "codes = merged_df.iloc[:, 0].to_numpy()\n",
    "\n",
    "code_grade_pairs = np.column_stack((codes, original_grade_pred.flatten()))\n",
    "\n",
    "code_grade_df = pd.DataFrame(code_grade_pairs, columns=[\"Code\", \"Predicted Grade\"])\n",
    "\n",
    "print(code_grade_df)\n",
    "\n",
    "code_grade_df.to_csv('output/test_grade_predictions.txt', sep=',', header=False, index=False)\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:36:27.166753Z",
     "start_time": "2024-01-18T23:36:27.134011Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
