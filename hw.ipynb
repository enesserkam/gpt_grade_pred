{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T16:55:19.562923Z",
     "start_time": "2024-01-19T16:55:19.548710Z"
    }
   },
   "outputs": [],
   "source": [
    "import re\n",
    "import os\n",
    "import tqdm\n",
    "from glob import glob\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from pprint import pprint\n",
    "import graphviz\n",
    "\n",
    "from collections import defaultdict\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.model_selection import train_test_split \n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import normalize\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from collections import Counter\n",
    "import gensim\n",
    "import nltk\n",
    "from gensim.models import KeyedVectors\n",
    "from gensim.models import Word2Vec\n",
    "from nltk.tokenize import word_tokenize\n",
    "from gensim.scripts.glove2word2vec import glove2word2vec\n",
    "\n",
    "from joblib import dump"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T16:50:55.172518Z",
     "start_time": "2024-01-19T16:50:31.092214Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 127/127 [00:24<00:00,  5.28it/s]\n"
     ]
    }
   ],
   "source": [
    "data_path = \"data/html/*.html\"\n",
    "\n",
    "code2convos = dict()\n",
    "\n",
    "pbar = tqdm.tqdm(sorted(list(glob(data_path))))\n",
    "for path in pbar:\n",
    "    # print(Path.cwd() / path)\n",
    "    file_code = os.path.basename(path).split(\".\")[0]\n",
    "    with open(path, \"r\", encoding=\"latin1\") as fh:\n",
    "            \n",
    "        # get the file id to use it as key later on\n",
    "        fid = os.path.basename(path).split(\".\")[0]\n",
    "\n",
    "        # read the html file\n",
    "        html_page = fh.read()\n",
    "\n",
    "        # parse the html file with bs4 so we can extract needed stuff\n",
    "        soup = BeautifulSoup(html_page, \"html.parser\")\n",
    "\n",
    "        # grab the conversations with the data-testid pattern\n",
    "        data_test_id_pattern = re.compile(r\"conversation-turn-[0-9]+\")\n",
    "        conversations = soup.find_all(\"div\", attrs={\"data-testid\": data_test_id_pattern})\n",
    "\n",
    "        convo_texts = []\n",
    "\n",
    "        for i, convo in enumerate(conversations):\n",
    "            convo = convo.find_all(\"div\", attrs={\"data-message-author-role\":re.compile( r\"[user|assistant]\") })\n",
    "            if len(convo) > 0:\n",
    "                role = convo[0].get(\"data-message-author-role\")\n",
    "                convo_texts.append({\n",
    "                        \"role\" : role,\n",
    "                        \"text\" : convo[0].text\n",
    "                    }\n",
    "                )\n",
    "                \n",
    "        code2convos[file_code] = convo_texts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T16:51:24.934234Z",
     "start_time": "2024-01-19T16:51:24.909077Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'role': 'user',\n",
      " 'text': 'Load a CSV file into a Pandas in Python. The file is named '\n",
      "         \"'cs412_hw1_dataset.csv' and contains columns like 'Species', \"\n",
      "         \"'Island', 'Sex', 'Diet', 'Year', 'Life Stage', 'Body Mass (g)', \"\n",
      "         \"'Bill Length (mm)', 'Bill Depth (mm)', 'Flipper Length (mm)', and \"\n",
      "         \"'Health Metrics'. \\n\"}\n"
     ]
    }
   ],
   "source": [
    "# let's see one of the conversations\n",
    "pprint(code2convos[\"0031c86e-81f4-4eef-9e0e-28037abf9883\"][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Things to do:\n",
    "- Prompt matching with questions\n",
    "- Feature Engineering\n",
    "- Question Grades preparation\n",
    "- Train/Test split\n",
    "- Fitting a model for predicting the scores"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Prompt Matching\n",
    "> We want to match the prompts with the questions in the Homework Let's\n",
    "> do it with a simple term frequency vectorizing method. For each prompt,\n",
    "> we will come with a vector that represents it. We will do the same\n",
    "> thing with each of the homework questions. Then, we will calculate the\n",
    "> vectors distanance to do the matching"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T16:51:28.300196Z",
     "start_time": "2024-01-19T16:51:28.287608Z"
    }
   },
   "outputs": [],
   "source": [
    "prompts = []\n",
    "code2prompts = defaultdict(list)\n",
    "for code , convos in code2convos.items():\n",
    "    user_prompts = []\n",
    "    for conv in convos:\n",
    "        if conv[\"role\"] == \"user\":\n",
    "            prompts.append(conv[\"text\"])\n",
    "            user_prompts.append(conv[\"text\"])\n",
    "    code2prompts[code] = user_prompts    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T16:51:35.256543Z",
     "start_time": "2024-01-19T16:51:35.238999Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "\"Load a CSV file into a Pandas in Python. The file is named 'cs412_hw1_dataset.csv' and contains columns like 'Species', 'Island', 'Sex', 'Diet', 'Year', 'Life Stage', 'Body Mass (g)', 'Bill Length (mm)', 'Bill Depth (mm)', 'Flipper Length (mm)', and 'Health Metrics'. \\n\""
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-19T16:51:36.119038Z",
     "start_time": "2024-01-19T16:51:36.101793Z"
    }
   },
   "outputs": [],
   "source": [
    "questions = [\n",
    "    \"\"\"Initialize\n",
    "*   First make a copy of the notebook given to you as a starter.\n",
    "*   Make sure you choose Connect form upper right.\n",
    "*   You may upload the data to the section on your left on Colab, than right click on the .csv file and get the path of the file by clicking on \"Copy Path\". You will be using it when loading the data.\n",
    "\n",
    "\"\"\",\n",
    "#####################\n",
    "    \"\"\"Load training dataset (5 pts)\n",
    "    *  Read the .csv file with the pandas library\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Understanding the dataset & Preprocessing (15 pts)\n",
    "Understanding the Dataset: (5 pts)\n",
    "> - Find the shape of the dataset (number of samples & number of attributes). (Hint: You can use the **shape** function)\n",
    "> - Display variable names (both dependent and independent).\n",
    "> - Display the summary of the dataset. (Hint: You can use the **info** function)\n",
    "> - Display the first 5 rows from training dataset. (Hint: You can use the **head** function)\n",
    "Preprocessing: (10 pts)\n",
    "\n",
    "> - Check if there are any missing values in the dataset. If there are, you can either drop these values or fill it with most common values in corresponding rows. **Be careful that you have enough data for training the  model.**\n",
    "\n",
    "> - Encode categorical labels with the mappings given in the cell below. (Hint: You can use **map** function)\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Set X & y, split data (5 pts)\n",
    "\n",
    "*   Shuffle the dataset.\n",
    "*   Seperate your dependent variable X, and your independent variable y. The column health_metrics is y, the rest is X.\n",
    "*   Split training and test sets as 80% and 20%, respectively.\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Features and Correlations (10 pts)\n",
    "\n",
    "* Correlations of features with health (4 points)\n",
    "Calculate the correlations for all features in dataset. Highlight any strong correlations with the target variable. Plot your results in a heatmap.\n",
    "\n",
    "* Feature Selection (3 points)\n",
    "Select a subset of features that are likely strong predictors, justifying your choices based on the computed correlations.\n",
    "\n",
    "* Hypothetical Driver Features (3 points)\n",
    "Propose two hypothetical features that could enhance the model's predictive accuracy for Y, explaining how they might be derived and their expected impact. Show the resulting correlations with target variable.\n",
    "\n",
    "* __Note:__ You get can get help from GPT.\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Tune Hyperparameters (20 pts)\n",
    "* Choose 2 hyperparameters to tune. You can use the Scikit learn decision tree documentation for the available hyperparameters *(Hyperparameters are listed under \"Parameters\" in the documentation)*. Use GridSearchCV for hyperparameter tuning, with a cross-validation value of 5. Use validation accuracy to pick the best hyper-parameter values. (15 pts)\n",
    "-Explain the hyperparameters you chose to tune. *(What are the hyperparameters you chose? Why did you choose them?)* (5 pts)\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Re-train and plot the decision tree with the hyperparameters you have chosen (15 pts)\n",
    "- Re-train model with the hyperparameters you have chosen in part 5). (10 pts)\n",
    "- Plot the tree you have trained. (5 pts)\n",
    "Hint: You can import the **plot_tree** function from the sklearn library.\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Test your classifier on the test set (20 pts)\n",
    "- Predict the labels of testing data using the tree you have trained in step 6. (10 pts)\n",
    "- Report the classification accuracy. (2 pts)\n",
    "- Plot & investigate the confusion matrix. Fill the following blanks. (8 pts)\n",
    "> The model most frequently mistakes class(es) _________ for class(es) _________.\n",
    "Hint: You can use the confusion_matrix function from sklearn.metrics\n",
    "\"\"\",\n",
    "#####################\n",
    "\"\"\"Find the information gain on the first split (10 pts)\"\"\",\n",
    "#####################\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "outputs": [
    {
     "data": {
      "text/plain": "\"\\nglove_input_file = 'glove/glove.6B.100d.txt'\\nword2vec_output_file = 'glove/glove.6B.100d.word2vec.txt'\\nglove2word2vec(glove_input_file, word2vec_output_file)\\n\\nglove_input_file = 'glove/glove.6B.50d.txt'\\nword2vec_output_file = 'glove/glove.6B.50d.word2vec.txt'\\nglove2word2vec(glove_input_file, word2vec_output_file)\\n\\nglove_input_file = 'glove/glove.6B.200d.txt'\\nword2vec_output_file = 'glove/glove.6B.200d.word2vec.txt'\\nglove2word2vec(glove_input_file, word2vec_output_file)\\n\""
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "glove_input_file = 'glove/glove.6B.100d.txt'\n",
    "word2vec_output_file = 'glove/glove.6B.100d.word2vec.txt'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\n",
    "glove_input_file = 'glove/glove.6B.50d.txt'\n",
    "word2vec_output_file = 'glove/glove.6B.50d.word2vec.txt'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\n",
    "glove_input_file = 'glove/glove.6B.200d.txt'\n",
    "word2vec_output_file = 'glove/glove.6B.200d.word2vec.txt'\n",
    "glove2word2vec(glove_input_file, word2vec_output_file)\n",
    "\"\"\""
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T16:51:37.037698Z",
     "start_time": "2024-01-19T16:51:37.001341Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "glove_model = KeyedVectors.load_word2vec_format('glove/glove.6B.50d.word2vec.txt', binary=False)\n",
    "dump(glove_model, 'joblib_models/glove_model_50d.joblib')\n",
    "def preprocess_and_tokenize(text):\n",
    "    words = word_tokenize(text.lower())\n",
    "    return [word for word in words if word.isalpha()]\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-19T16:56:12.707685Z",
     "start_time": "2024-01-19T16:55:55.144653Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def vectorize_prompts(prompts, model):\n",
    "    vectorized = []\n",
    "    for prompt in prompts:\n",
    "        words = preprocess_and_tokenize(prompt)\n",
    "        word_vectors = [model[word] for word in words if word in model.key_to_index]\n",
    "\n",
    "        if len(word_vectors) == 0:\n",
    "            vectorized.append(np.zeros(model.vector_size))  \n",
    "        else:\n",
    "            vectorized.append(np.mean(word_vectors, axis=0)) \n",
    "\n",
    "    return pd.DataFrame(vectorized)\n",
    "\n",
    "code2prompts_glove = dict()\n",
    "\n",
    "for code, user_prompts in code2prompts.items():\n",
    "    if len(user_prompts) > 0:\n",
    "        vectorized_df = vectorize_prompts(user_prompts, glove_model)\n",
    "        code2prompts_glove[code] = vectorized_df\n",
    "    else:\n",
    "        print(f\"{code}.html has no prompts\")\n",
    "        \n",
    "print(code2prompts_glove[\"089eb66d-4c3a-4f58-b98f-a3774a2efb34\"].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "code2prompts_glove[\"089eb66d-4c3a-4f58-b98f-a3774a2efb34\"].head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer()\n",
    "vectorizer = vectorizer.fit(prompts + questions)\n",
    "questions_TF_IDF = pd.DataFrame(vectorizer.transform(questions).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "questions_TF_IDF.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "code2prompts_tf_idf = dict()\n",
    "for code, user_prompts in code2prompts.items():\n",
    "    if len(user_prompts) == 0:\n",
    "        print(code+\".html\")\n",
    "        continue\n",
    "    prompts_TF_IDF = pd.DataFrame(vectorizer.transform(user_prompts).toarray(), columns=vectorizer.get_feature_names_out())\n",
    "    code2prompts_tf_idf[code] = prompts_TF_IDF"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code2prompts_tf_idf[\"089eb66d-4c3a-4f58-b98f-a3774a2efb34\"].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code2cosine = dict()\n",
    "for code, user_prompts_tf_idf in code2prompts_tf_idf.items():\n",
    "    code2cosine[code] = pd.DataFrame(cosine_similarity(questions_TF_IDF,user_prompts_tf_idf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "code2cosine[\"089eb66d-4c3a-4f58-b98f-a3774a2efb34\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "question_of_prompts = dict()\n",
    "\n",
    "for code, df in code2cosine.items():\n",
    "    max_indices = []\n",
    "\n",
    "    for col in df.columns:\n",
    "        max_index = df[col].idxmax()\n",
    "\n",
    "        max_indices.append(max_index)\n",
    "\n",
    "    question_of_prompts[code] = max_indices\n",
    "    \n",
    "question_of_prompts[\"089eb66d-4c3a-4f58-b98f-a3774a2efb34\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "code2prompts_glove[\"089eb66d-4c3a-4f58-b98f-a3774a2efb34\"].shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "num_questions = len(questions)\n",
    "\n",
    "new_code_counts = dict()\n",
    "\n",
    "for code, indices in question_of_prompts.items():\n",
    "    counts = Counter(indices)\n",
    "\n",
    "    count_vector = [counts.get(i, 0) for i in range(num_questions)]\n",
    "\n",
    "    new_code_counts[code] = count_vector\n",
    "\n",
    "new_code_counts[\"04f91058-d0f8-4324-83b2-19c671f433dc\"]"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "vector_size = 50   \n",
    "\n",
    "final_df = pd.DataFrame(index=code2prompts_glove.keys(), columns=[f'q{i}_feature_{j}' for i in range(num_questions) for j in range(vector_size)])\n",
    "\n",
    "for code in code2prompts_glove.keys():\n",
    "    glove_vectors = code2prompts_glove[code]\n",
    "    question_indices = question_of_prompts[code]\n",
    "\n",
    "    summed_vectors = np.zeros((num_questions, vector_size))\n",
    "    prompt_counts = Counter(question_indices)\n",
    "\n",
    "    for vector, question_idx in zip(glove_vectors, question_indices):\n",
    "        scaled_vector = vector / prompt_counts[question_idx]\n",
    "        summed_vectors[question_idx] += scaled_vector\n",
    "\n",
    "    for i in range(num_questions):\n",
    "        column_labels = [f'q{i}_feature_{j}' for j in range(vector_size)]\n",
    "        final_df.loc[code, column_labels] = summed_vectors[i]\n",
    "\n",
    "final_df.rename_axis('code', inplace=True)\n",
    "final_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "scaler = StandardScaler()\n",
    "\n",
    "normalized_data = scaler.fit_transform(final_df)\n",
    "\n",
    "normalized_df = pd.DataFrame(normalized_data, index=final_df.index, columns=final_df.columns)\n",
    "\n",
    "normalized_df.rename_axis('code', inplace=True)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering\n",
    "- Number of prompts that a user asked\n",
    "- Number of complaints that a user makes e.g \"the code gives this error!\"\n",
    "- User prompts average number of characters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "coefficients = [0.1,0.05,0.15,0.05,0.1,0.2,0.15,0.1,0.1]\n",
    "\n",
    "modified_code_counts = {}\n",
    "\n",
    "for code, count_vector in new_code_counts.items():\n",
    "    modified_vector = [count * coeff for count, coeff in zip(count_vector, coefficients)]\n",
    "    modified_code_counts[code] = modified_vector\n",
    "\n",
    "modified_counts_df = pd.DataFrame.from_dict(modified_code_counts, orient='index')\n",
    "\n",
    "modified_counts_df.index.name = 'code'\n",
    "\n",
    "extended_df = normalized_df.merge(modified_counts_df, left_on='code', right_index=True)\n",
    "\n",
    "modified_count_col_names = [f'modified_count_{i}' for i in range(num_questions)]\n",
    "extended_df.rename(columns=dict(zip(range(num_questions), modified_count_col_names)), inplace=True)\n",
    "\n",
    "extended_df.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "code2questionmapping = dict()\n",
    "for code, cosine_scores in code2cosine.items():\n",
    "    code2questionmapping[code] = code2cosine[code].max(axis=1).tolist()\n",
    "\n",
    "question_mapping_scores = pd.DataFrame(code2questionmapping).T\n",
    "question_mapping_scores.reset_index(inplace=True)\n",
    "question_mapping_scores.rename(columns={i: f\"Q_{i}\" for i in range(len(questions))}, inplace=True)\n",
    "question_mapping_scores.rename(columns={\"index\" : \"code\"}, inplace=True)\n",
    "\n",
    "question_mapping_scores.head()"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [
    "merged_df = question_mapping_scores.merge(extended_df, on='code', how='left')\n",
    "# merged_df = question_mapping_scores.merge(modified_counts_df, on='code', how='left')\n",
    "merged_df.shape"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading the scores\n",
    "scores = pd.read_csv(\"data/scores.csv\", sep=\",\")\n",
    "scores[\"code\"] = scores[\"code\"].apply(lambda x: x.strip())\n",
    "\n",
    "# selecting the columns we need and we care\n",
    "scores = scores[[\"code\", \"grade\"]]\n",
    "\n",
    "# show some examples\n",
    "scores.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's check grades distribution\n",
    "\n",
    "plt.title('Histogram Grades')\n",
    "plt.hist(scores[\"grade\"], rwidth=.8, bins=np.arange(min(scores[\"grade\"]), max(scores[\"grade\"])+2) - 0.5)\n",
    "plt.ylabel('Count')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Merging scores with features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 438,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T23:32:36.194735Z",
     "start_time": "2024-01-18T23:32:36.130263Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "                                   code       Q_0       Q_1       Q_2  \\\n1  0225686d-b825-4cac-8691-3a3a5343df2b  0.192013  0.795607  0.772184   \n2  041f950b-c013-409a-a642-cffff60b9d4b  0.258306  0.295923  0.624824   \n3  04f91058-d0f8-4324-83b2-19c671f433dc  0.145965  0.117841  0.267346   \n4  089eb66d-4c3a-4f58-b98f-a3774a2efb34  0.344182  0.575528  0.782883   \n5  090d6217-5d69-4929-a342-19abab78324f  0.181981  0.716248  0.654161   \n\n        Q_3       Q_4       Q_5       Q_6       Q_7       Q_8  ...  \\\n1  0.882656  0.607114  0.987511  0.892586  0.570741  0.543866  ...   \n2  0.351872  0.643038  0.454314  0.540269  0.546506  0.325793  ...   \n3  0.316809  0.333889  0.309084  0.192434  0.261892  0.407106  ...   \n4  0.624833  0.724872  0.872171  0.684797  0.945305  0.511769  ...   \n5  0.710065  0.678797  0.872171  0.794699  0.652518  0.810325  ...   \n\n   modified_count_0  modified_count_1  modified_count_2  modified_count_3  \\\n1               0.0              0.05              0.75              0.05   \n2               0.0              0.00              0.30              0.15   \n3               0.0              0.00              0.90              0.15   \n4               0.5              0.05              2.85              0.75   \n5               0.0              0.25              2.25              0.65   \n\n   modified_count_4  modified_count_5  modified_count_6  modified_count_7  \\\n1               0.4               0.4              0.15               0.3   \n2               0.1               0.0              0.30               0.1   \n3               0.6               0.2              0.15               0.2   \n4               1.7               1.8              1.05               0.4   \n5               1.0               1.4              0.90               0.5   \n\n   modified_count_8     grade  \n1               0.1  0.816992  \n2               0.0 -0.553696  \n3               0.1  0.512395  \n4               0.9  0.969291  \n5               1.2 -1.467488  \n\n[5 rows x 470 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>code</th>\n      <th>Q_0</th>\n      <th>Q_1</th>\n      <th>Q_2</th>\n      <th>Q_3</th>\n      <th>Q_4</th>\n      <th>Q_5</th>\n      <th>Q_6</th>\n      <th>Q_7</th>\n      <th>Q_8</th>\n      <th>...</th>\n      <th>modified_count_0</th>\n      <th>modified_count_1</th>\n      <th>modified_count_2</th>\n      <th>modified_count_3</th>\n      <th>modified_count_4</th>\n      <th>modified_count_5</th>\n      <th>modified_count_6</th>\n      <th>modified_count_7</th>\n      <th>modified_count_8</th>\n      <th>grade</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>0225686d-b825-4cac-8691-3a3a5343df2b</td>\n      <td>0.192013</td>\n      <td>0.795607</td>\n      <td>0.772184</td>\n      <td>0.882656</td>\n      <td>0.607114</td>\n      <td>0.987511</td>\n      <td>0.892586</td>\n      <td>0.570741</td>\n      <td>0.543866</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.05</td>\n      <td>0.75</td>\n      <td>0.05</td>\n      <td>0.4</td>\n      <td>0.4</td>\n      <td>0.15</td>\n      <td>0.3</td>\n      <td>0.1</td>\n      <td>0.816992</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>041f950b-c013-409a-a642-cffff60b9d4b</td>\n      <td>0.258306</td>\n      <td>0.295923</td>\n      <td>0.624824</td>\n      <td>0.351872</td>\n      <td>0.643038</td>\n      <td>0.454314</td>\n      <td>0.540269</td>\n      <td>0.546506</td>\n      <td>0.325793</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.30</td>\n      <td>0.15</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>0.30</td>\n      <td>0.1</td>\n      <td>0.0</td>\n      <td>-0.553696</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>04f91058-d0f8-4324-83b2-19c671f433dc</td>\n      <td>0.145965</td>\n      <td>0.117841</td>\n      <td>0.267346</td>\n      <td>0.316809</td>\n      <td>0.333889</td>\n      <td>0.309084</td>\n      <td>0.192434</td>\n      <td>0.261892</td>\n      <td>0.407106</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.00</td>\n      <td>0.90</td>\n      <td>0.15</td>\n      <td>0.6</td>\n      <td>0.2</td>\n      <td>0.15</td>\n      <td>0.2</td>\n      <td>0.1</td>\n      <td>0.512395</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>089eb66d-4c3a-4f58-b98f-a3774a2efb34</td>\n      <td>0.344182</td>\n      <td>0.575528</td>\n      <td>0.782883</td>\n      <td>0.624833</td>\n      <td>0.724872</td>\n      <td>0.872171</td>\n      <td>0.684797</td>\n      <td>0.945305</td>\n      <td>0.511769</td>\n      <td>...</td>\n      <td>0.5</td>\n      <td>0.05</td>\n      <td>2.85</td>\n      <td>0.75</td>\n      <td>1.7</td>\n      <td>1.8</td>\n      <td>1.05</td>\n      <td>0.4</td>\n      <td>0.9</td>\n      <td>0.969291</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>090d6217-5d69-4929-a342-19abab78324f</td>\n      <td>0.181981</td>\n      <td>0.716248</td>\n      <td>0.654161</td>\n      <td>0.710065</td>\n      <td>0.678797</td>\n      <td>0.872171</td>\n      <td>0.794699</td>\n      <td>0.652518</td>\n      <td>0.810325</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.25</td>\n      <td>2.25</td>\n      <td>0.65</td>\n      <td>1.0</td>\n      <td>1.4</td>\n      <td>0.90</td>\n      <td>0.5</td>\n      <td>1.2</td>\n      <td>-1.467488</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 470 columns</p>\n</div>"
     },
     "execution_count": 438,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "temp_df = pd.merge(merged_df, scores, on='code', how=\"left\")\n",
    "temp_df.dropna(inplace=True)\n",
    "temp_df.drop_duplicates(\"code\",inplace=True, keep=\"first\")\n",
    "\n",
    "temp_df = temp_df[temp_df['grade'] >= 70]\n",
    "\n",
    "temp_df['grade'] = temp_df['grade'] - 70\n",
    "\n",
    "scaler = StandardScaler()\n",
    "\n",
    "temp_df['grade'] = scaler.fit_transform(temp_df[['grade']])\n",
    "dump(scaler, 'scaler.joblib')\n",
    "temp_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = temp_df[temp_df.columns[1:-1]].to_numpy()\n",
    "y = temp_df[\"grade\"].to_numpy()\n",
    "print(X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Train/Test split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 435,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T23:27:05.442740Z",
     "start_time": "2024-01-18T23:27:05.420458Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 94\n",
      "Test set size: 24\n"
     ]
    },
    {
     "data": {
      "text/plain": "(94, 468)"
     },
     "execution_count": 435,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(\"Train set size:\", len(X_train))\n",
    "print(\"Test set size:\", len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Fitting a model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Predicting and Analyzing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T23:09:15.703477Z",
     "start_time": "2024-01-18T23:09:15.658629Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "['412_model.joblib']"
     },
     "execution_count": 425,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from joblib import dump\n",
    "\n",
    "regressor = DecisionTreeRegressor(random_state=0,criterion='squared_error', max_depth=5)\n",
    "regressor.fit(X_train, y_train)\n",
    "\n",
    "dump(regressor, '412_model.joblib')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-01-18T23:10:01.073732Z",
     "start_time": "2024-01-18T23:10:01.053841Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Node 0 has MSE 0.9058181813259566\n",
      "Node 1 has MSE 1.2586574827217656\n",
      "Node 2 has MSE 1.3932309919328423\n",
      "Node 3 has MSE 0.5860256410474337\n",
      "Node 4 has MSE 0.005798718984516116\n",
      "Node 5 has MSE 0.0\n",
      "Node 6 has MSE -1.1102230246251565e-16\n",
      "Node 7 has MSE 0.11504658465280149\n",
      "Node 8 has MSE 0.0\n",
      "Node 9 has MSE 0.015946477207419762\n",
      "Node 10 has MSE 0.939155793084093\n",
      "Node 11 has MSE 0.2996004808666708\n",
      "Node 12 has MSE 0.08553110502161232\n",
      "Node 13 has MSE 0.023194875938067128\n",
      "Node 14 has MSE 1.984089975648473e-15\n",
      "Node 15 has MSE 0.6452159118283847\n",
      "Node 16 has MSE 0.44323958237895744\n",
      "Node 17 has MSE 0.10824275437763592\n",
      "Node 18 has MSE 0.0057987189845162546\n",
      "Node 19 has MSE -2.220446049250313e-16\n",
      "Node 20 has MSE 0.3121014667642568\n",
      "Node 21 has MSE 0.07731625312688267\n",
      "Node 22 has MSE 0.32472826313290726\n",
      "Node 23 has MSE 0.036080918125879435\n",
      "Node 24 has MSE 0.005798718984516116\n",
      "Node 25 has MSE 0.0\n",
      "Node 26 has MSE -4.440892098500626e-16\n",
      "Node 27 has MSE -4.440892098500626e-16\n",
      "Node 28 has MSE 0.43532312711924115\n",
      "Node 29 has MSE 0.3056457440256989\n",
      "Node 30 has MSE 0.26353979702191344\n",
      "Node 31 has MSE 0.1793737072543684\n",
      "Node 32 has MSE 0.10981449481749894\n",
      "Node 33 has MSE 0.2522682374751528\n",
      "Node 34 has MSE 0.43142469244800447\n",
      "Node 35 has MSE 0.32988268000803306\n",
      "Node 36 has MSE 0.11017566070580792\n",
      "Node 37 has MSE 3.552713678800501e-15\n",
      "Node 38 has MSE 0.8034705024945634\n",
      "Node 39 has MSE 0.005154416875125634\n",
      "Node 40 has MSE 0.0\n",
      "Node 41 has MSE 0.0\n",
      "Node 42 has MSE 0.052188470860646125\n",
      "Node 43 has MSE 0.0\n",
      "Node 44 has MSE -1.6653345369377348e-16\n"
     ]
    }
   ],
   "source": [
    "extracted_MSEs = regressor.tree_.impurity   \n",
    "for idx, MSE in enumerate(regressor.tree_.impurity):\n",
    "    print(\"Node {} has MSE {}\".format(idx,MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 428,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE Train: 0.12114147881199924\n",
      "MSE TEST: 2.0223849512949665\n",
      "R2 Train: 0.8662629197454729\n",
      "R2 TEST: -0.510209863091617\n"
     ]
    }
   ],
   "source": [
    "# Prediction\n",
    "y_train_pred = regressor.predict(X_train)\n",
    "y_test_pred = regressor.predict(X_test)\n",
    "\n",
    "# Calculation of Mean Squared Error (MSE)\n",
    "print(\"MSE Train:\", mean_squared_error(y_train,y_train_pred))\n",
    "print(\"MSE TEST:\", mean_squared_error(y_test,y_test_pred))\n",
    "\n",
    "print(\"R2 Train:\", r2_score(y_train,y_train_pred))\n",
    "print(\"R2 TEST:\", r2_score(y_test,y_test_pred))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:10:09.769267Z",
     "start_time": "2024-01-18T23:10:09.751922Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 429,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Lasso Regression:\n",
      "MSE Train: 0.6189626326236027\n",
      "MSE Test: 1.9058543100748302\n",
      "R2 Train: 0.3166811559053144\n",
      "R2 Test: -0.42319095820392305\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import Lasso\n",
    "\n",
    "lasso_regressor = Lasso(alpha=0.01, random_state=0)  \n",
    "lasso_regressor.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_lasso = lasso_regressor.predict(X_train)\n",
    "y_test_pred_lasso = lasso_regressor.predict(X_test)\n",
    "\n",
    "print(\"\\nLasso Regression:\")\n",
    "print(\"MSE Train:\", mean_squared_error(y_train, y_train_pred_lasso))\n",
    "print(\"MSE Test:\", mean_squared_error(y_test, y_test_pred_lasso))\n",
    "print(\"R2 Train:\", r2_score(y_train, y_train_pred_lasso))\n",
    "print(\"R2 Test:\", r2_score(y_test, y_test_pred_lasso))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:10:12.175514Z",
     "start_time": "2024-01-18T23:10:12.130055Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 430,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Principal Component Regression:\n",
      "MSE Train: 0.7723967766238682\n",
      "MSE Test: 1.6259881278969333\n",
      "R2 Train: 0.14729380294264227\n",
      "R2 Test: -0.21420173070783166\n"
     ]
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "pca = PCA(n_components=0.95)  # Keep 95% of variance\n",
    "linear_reg = LinearRegression()\n",
    "pcr = make_pipeline(pca, linear_reg)\n",
    "\n",
    "pcr.fit(X_train, y_train)\n",
    "\n",
    "y_train_pred_pcr = pcr.predict(X_train)\n",
    "y_test_pred_pcr = pcr.predict(X_test)\n",
    "\n",
    "print(\"\\nPrincipal Component Regression:\")\n",
    "print(\"MSE Train:\", mean_squared_error(y_train, y_train_pred_pcr))\n",
    "print(\"MSE Test:\", mean_squared_error(y_test, y_test_pred_pcr))\n",
    "print(\"R2 Train:\", r2_score(y_train, y_train_pred_pcr))\n",
    "print(\"R2 Test:\", r2_score(y_test, y_test_pred_pcr))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:10:13.425381Z",
     "start_time": "2024-01-18T23:10:13.390677Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 433,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Regressor:\n",
      "MSE Train: 0.1284448641532753\n",
      "MSE Test: 1.427212730230189\n",
      "R2 Train: 0.8582001699664993\n",
      "R2 Test: -0.06576680198466378\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "\n",
    "random_forest_regressor = RandomForestRegressor(random_state=42, n_estimators=40)  # n_estimators can be adjusted\n",
    "\n",
    "random_forest_regressor.fit(X_train, y_train)\n",
    "dump(random_forest_regressor, '412_rf_model.joblib')\n",
    "\n",
    "y_train_pred_rf = random_forest_regressor.predict(X_train)\n",
    "y_test_pred_rf = random_forest_regressor.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Regressor:\")\n",
    "print(\"MSE Train:\", mean_squared_error(y_train, y_train_pred_rf))\n",
    "print(\"MSE Test:\", mean_squared_error(y_test, y_test_pred_rf))\n",
    "\n",
    "print(\"R2 Train:\", r2_score(y_train, y_train_pred_rf))\n",
    "print(\"R2 Test:\", r2_score(y_test, y_test_pred_rf))\n"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:13:02.493187Z",
     "start_time": "2024-01-18T23:13:01.387858Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 432,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Ensemble Model with Decision Tree Regressor:\n",
      "MSE Train: 1.5981120815128126e-33\n",
      "MSE Test: 1.524096639763676\n",
      "R2 Train: 1.0\n",
      "R2 Test: -0.13811456923770837\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "In this cell, almost all combinations have been tried.\n",
    "PCA+RF, RF+Lasso, Lasso+RF, RF + Average, PCR + Average and etc.\n",
    "\"\"\"\n",
    "\n",
    "X_train_ensemble = np.column_stack((y_train_pred_rf, y_train_pred_lasso)) \n",
    "X_test_ensemble = np.column_stack((y_test_pred_rf, y_test_pred_lasso))\n",
    "\n",
    "ensemble_regressor = DecisionTreeRegressor(random_state=42)\n",
    "ensemble_regressor.fit(X_train_ensemble, y_train)\n",
    "\n",
    "y_train_pred_ensemble = ensemble_regressor.predict(X_train_ensemble)\n",
    "y_test_pred_ensemble = ensemble_regressor.predict(X_test_ensemble)\n",
    "\n",
    "print(\"Ensemble Model with Decision Tree Regressor:\")\n",
    "print(\"MSE Train:\", mean_squared_error(y_train, y_train_pred_ensemble))\n",
    "print(\"MSE Test:\", mean_squared_error(y_test, y_test_pred_ensemble))\n",
    "print(\"R2 Train:\", r2_score(y_train, y_train_pred_ensemble))\n",
    "print(\"R2 Test:\", r2_score(y_test, y_test_pred_ensemble))"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-01-18T23:10:17.735140Z",
     "start_time": "2024-01-18T23:10:17.674315Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "outputs": [],
   "source": [],
   "metadata": {
    "collapsed": false
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
